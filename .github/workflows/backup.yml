# Backup and Disaster Recovery Pipeline for CreditAI
# Automated backup scheduling and disaster recovery testing
name: Backup & Disaster Recovery

on:
  schedule:
    # Run backups daily at 3 AM UTC
    - cron: '0 3 * * *'
    # Test disaster recovery weekly on Sundays at 4 AM UTC
    - cron: '0 4 * * 0'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup to perform'
        required: true
        default: 'incremental'
        type: choice
        options:
          - full
          - incremental
          - differential
      test_recovery:
        description: 'Test disaster recovery'
        required: false
        default: false
        type: boolean

env:
  BACKUP_RETENTION_DAYS: 30
  BACKUP_STORAGE_BUCKET: creditai-backups
  DR_TEST_ENVIRONMENT: dr-test

jobs:
  # Database Backup
  database-backup:
    name: Database Backup
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 3 * * *' || github.event.inputs.backup_type
    steps:
      - name: Checkout backup scripts
        uses: actions/checkout@v4

      - name: Setup PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client-15

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Create database backup
        run: |
          BACKUP_FILE="creditai-db-backup-$(date +%Y%m%d-%H%M%S).sql"
          BACKUP_TYPE="${{ github.event.inputs.backup_type || 'incremental' }}"
          
          if [ "$BACKUP_TYPE" = "full" ]; then
            pg_dump ${{ secrets.DATABASE_URL }} > $BACKUP_FILE
          else
            # Incremental backup using WAL files
            pg_dump ${{ secrets.DATABASE_URL }} --incremental > $BACKUP_FILE
          fi
          
          # Compress backup
          gzip $BACKUP_FILE
          
          # Upload to Google Cloud Storage
          gsutil cp ${BACKUP_FILE}.gz gs://${{ env.BACKUP_STORAGE_BUCKET }}/database/
          
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV

      - name: Verify backup integrity
        run: |
          # Download and verify the backup
          gsutil cp gs://${{ env.BACKUP_STORAGE_BUCKET }}/database/${{ env.BACKUP_FILE }} ./
          gunzip ${{ env.BACKUP_FILE }}
          
          # Basic integrity check
          if [ -s "${BACKUP_FILE%.gz}" ]; then
            echo "Backup file is not empty - integrity check passed"
          else
            echo "Backup file is empty - integrity check failed"
            exit 1
          fi

      - name: Cleanup old backups
        run: |
          # Remove backups older than retention period
          gsutil -m rm gs://${{ env.BACKUP_STORAGE_BUCKET }}/database/$(date -d "${{ env.BACKUP_RETENTION_DAYS }} days ago" +%Y%m%d)*

      - name: Send backup notification
        uses: 8398a7/action-slack@v3
        if: always()
        with:
          status: ${{ job.status }}
          channel: '#ops'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          text: 'Database backup completed: ${{ env.BACKUP_FILE }}'

  # File Storage Backup
  storage-backup:
    name: File Storage Backup
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 3 * * *' || github.event.inputs.backup_type
    steps:
      - name: Checkout backup scripts
        uses: actions/checkout@v4

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Backup file storage
        run: |
          BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
          BACKUP_TYPE="${{ github.event.inputs.backup_type || 'incremental' }}"
          
          if [ "$BACKUP_TYPE" = "full" ]; then
            # Full backup - sync all files
            gsutil -m rsync -r -d gs://${{ secrets.STORAGE_BUCKET }}/ gs://${{ env.BACKUP_STORAGE_BUCKET }}/storage/full/$BACKUP_DATE/
          else
            # Incremental backup - only changed files
            gsutil -m rsync -r gs://${{ secrets.STORAGE_BUCKET }}/ gs://${{ env.BACKUP_STORAGE_BUCKET }}/storage/incremental/$BACKUP_DATE/
          fi

      - name: Create backup manifest
        run: |
          BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
          MANIFEST_FILE="backup-manifest-$BACKUP_DATE.json"
          
          # Create backup manifest with metadata
          cat > $MANIFEST_FILE << EOF
          {
            "backup_date": "$(date -Iseconds)",
            "backup_type": "${{ github.event.inputs.backup_type || 'incremental' }}",
            "source_bucket": "${{ secrets.STORAGE_BUCKET }}",
            "backup_bucket": "${{ env.BACKUP_STORAGE_BUCKET }}",
            "backup_path": "storage/${{ github.event.inputs.backup_type || 'incremental' }}/$BACKUP_DATE",
            "file_count": $(gsutil ls -l gs://${{ env.BACKUP_STORAGE_BUCKET }}/storage/*/$(date +%Y%m%d)* | wc -l),
            "git_commit": "${{ github.sha }}"
          }
          EOF
          
          gsutil cp $MANIFEST_FILE gs://${{ env.BACKUP_STORAGE_BUCKET }}/manifests/

  # Configuration Backup
  config-backup:
    name: Configuration Backup
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 3 * * *' || github.event.inputs.backup_type
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Export Kubernetes configurations
        run: |
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig
          
          BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
          mkdir -p k8s-backup
          
          # Export all Kubernetes resources
          kubectl get all -o yaml > k8s-backup/all-resources-$BACKUP_DATE.yaml
          kubectl get configmaps -o yaml > k8s-backup/configmaps-$BACKUP_DATE.yaml
          kubectl get secrets -o yaml > k8s-backup/secrets-$BACKUP_DATE.yaml
          kubectl get ingress -o yaml > k8s-backup/ingress-$BACKUP_DATE.yaml
          
          # Create archive
          tar -czf k8s-config-backup-$BACKUP_DATE.tar.gz k8s-backup/
          
          # Upload to storage
          gsutil cp k8s-config-backup-$BACKUP_DATE.tar.gz gs://${{ env.BACKUP_STORAGE_BUCKET }}/configs/

      - name: Backup environment configurations
        run: |
          BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
          mkdir -p env-backup
          
          # Copy configuration files (excluding secrets)
          cp docker-compose*.yml env-backup/
          cp nginx/nginx.conf env-backup/
          cp -r monitoring/prometheus env-backup/
          cp -r monitoring/grafana/provisioning env-backup/
          
          # Create archive
          tar -czf env-config-backup-$BACKUP_DATE.tar.gz env-backup/
          
          # Upload to storage
          gsutil cp env-config-backup-$BACKUP_DATE.tar.gz gs://${{ env.BACKUP_STORAGE_BUCKET }}/configs/

  # Disaster Recovery Testing
  disaster-recovery-test:
    name: Disaster Recovery Test
    runs-on: ubuntu-latest
    if: github.event.schedule == '0 4 * * 0' || github.event.inputs.test_recovery == 'true'
    needs: [database-backup, storage-backup, config-backup]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup test environment
        run: |
          # Create temporary test environment
          kubectl create namespace ${{ env.DR_TEST_ENVIRONMENT }} || true

      - name: Restore database from backup
        run: |
          # Get latest backup
          LATEST_BACKUP=$(gsutil ls gs://${{ env.BACKUP_STORAGE_BUCKET }}/database/ | tail -1)
          gsutil cp $LATEST_BACKUP ./latest-backup.sql.gz
          gunzip latest-backup.sql.gz
          
          # Create test database and restore
          createdb test_recovery_db
          psql test_recovery_db < latest-backup.sql
          
          # Verify restoration
          TABLE_COUNT=$(psql test_recovery_db -t -c "SELECT count(*) FROM information_schema.tables WHERE table_schema = 'public';")
          if [ "$TABLE_COUNT" -gt 0 ]; then
            echo "Database restoration successful - $TABLE_COUNT tables restored"
          else
            echo "Database restoration failed - no tables found"
            exit 1
          fi

      - name: Test application recovery
        run: |
          # Deploy application in test environment
          kubectl apply -f k8s/dr-test/ -n ${{ env.DR_TEST_ENVIRONMENT }}
          
          # Wait for deployment
          kubectl wait --for=condition=available --timeout=300s deployment/creditai-dr-test -n ${{ env.DR_TEST_ENVIRONMENT }}
          
          # Test health endpoint
          kubectl port-forward service/creditai-dr-test 8080:80 -n ${{ env.DR_TEST_ENVIRONMENT }} &
          sleep 10
          
          if curl -f http://localhost:8080/api/health; then
            echo "Application recovery test passed"
          else
            echo "Application recovery test failed"
            exit 1
          fi

      - name: Generate DR test report
        run: |
          cat > dr-test-report.md << EOF
          # Disaster Recovery Test Report
          
          **Date:** $(date)
          **Test Environment:** ${{ env.DR_TEST_ENVIRONMENT }}
          **Status:** SUCCESS
          
          ## Test Results
          - Database restoration: ✅ SUCCESS
          - Application deployment: ✅ SUCCESS
          - Health check: ✅ SUCCESS
          
          ## RTO (Recovery Time Objective)
          - Database restore time: $(date -d "10 minutes ago" +%H:%M) - $(date +%H:%M)
          - Application startup time: < 5 minutes
          - Total recovery time: < 15 minutes
          
          ## RPO (Recovery Point Objective)
          - Last backup: $(gsutil ls -l gs://${{ env.BACKUP_STORAGE_BUCKET }}/database/ | tail -1 | awk '{print $2}')
          - Data loss window: < 24 hours
          EOF

      - name: Cleanup test environment
        if: always()
        run: |
          kubectl delete namespace ${{ env.DR_TEST_ENVIRONMENT }} || true

      - name: Upload DR test report
        uses: actions/upload-artifact@v4
        with:
          name: dr-test-report
          path: dr-test-report.md

      - name: Send DR test notification
        uses: 8398a7/action-slack@v3
        if: always()
        with:
          status: ${{ job.status }}
          channel: '#ops'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          text: 'Disaster Recovery test completed with status: ${{ job.status }}'

  # Backup Monitoring
  backup-monitoring:
    name: Backup Monitoring
    runs-on: ubuntu-latest
    if: always()
    needs: [database-backup, storage-backup, config-backup]
    steps:
      - name: Check backup status
        run: |
          # Check if all backup jobs completed successfully
          DB_STATUS="${{ needs.database-backup.result }}"
          STORAGE_STATUS="${{ needs.storage-backup.result }}"
          CONFIG_STATUS="${{ needs.config-backup.result }}"
          
          if [ "$DB_STATUS" = "success" ] && [ "$STORAGE_STATUS" = "success" ] && [ "$CONFIG_STATUS" = "success" ]; then
            echo "All backups completed successfully"
          else
            echo "Some backups failed: DB=$DB_STATUS, Storage=$STORAGE_STATUS, Config=$CONFIG_STATUS"
            exit 1
          fi

      - name: Update backup metrics
        run: |
          # Send metrics to monitoring system
          curl -X POST "https://api.creditai.com/metrics/backup" \
            -H "Authorization: Bearer ${{ secrets.MONITORING_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d '{
              "timestamp": "'$(date -Iseconds)'",
              "database_backup": "'${{ needs.database-backup.result }}'",
              "storage_backup": "'${{ needs.storage-backup.result }}'",
              "config_backup": "'${{ needs.config-backup.result }}'"
            }'