// AI Model Configuration
// Auto-generated by setup-ai-model-deployment.js

export interface ModelConfig {
  name: string;
  provider: string;
  endpoint: string;
  apiKey: string;
  maxTokens: number;
  temperature: number;
  rateLimits: {
    requestsPerMinute: number;
    tokensPerMinute: number;
  };
}

export interface AIDeploymentConfig {
  models: {
    primary: ModelConfig;
    secondary: ModelConfig;
    validation: ModelConfig;
  };
  cache: {
    redis: {
      host: string;
      port: number;
      password?: string;
      ttl: number;
      maxMemory: string;
    };
  };
  monitoring: {
    metrics: {
      enabled: boolean;
      interval: number;
      retention: string;
    };
    alerts: {
      errorRate: number;
      responseTime: number;
      availability: number;
    };
  };
}

export const AI_DEPLOYMENT_CONFIG: AIDeploymentConfig = {
  "models": {
    "primary": {
      "name": "gemini-pro",
      "provider": "google",
      "endpoint": process.env.GOOGLE_AI_ENDPOINT || "https://generativelanguage.googleapis.com/v1beta",
      "apiKey": process.env.GOOGLE_AI_API_KEY || "",
      "maxTokens": 8192,
      "temperature": 0.1,
      "rateLimits": {
        "requestsPerMinute": 60,
        "tokensPerMinute": 32000
      }
    },
    "secondary": {
      "name": "gpt-4",
      "provider": "openai",
      "endpoint": process.env.OPENAI_API_ENDPOINT || "https://api.openai.com/v1",
      "apiKey": process.env.OPENAI_API_KEY || "",
      "maxTokens": 8192,
      "temperature": 0.1,
      "rateLimits": {
        "requestsPerMinute": 50,
        "tokensPerMinute": 40000
      }
    },
    "validation": {
      "name": "claude-3-haiku",
      "provider": "anthropic",
      "endpoint": process.env.ANTHROPIC_API_ENDPOINT || "https://api.anthropic.com/v1",
      "apiKey": process.env.ANTHROPIC_API_KEY || "",
      "maxTokens": 4096,
      "temperature": 0.0,
      "rateLimits": {
        "requestsPerMinute": 100,
        "tokensPerMinute": 50000
      }
    }
  },
  "cache": {
    "redis": {
      "host": process.env.REDIS_HOST || "localhost",
      "port": parseInt(process.env.REDIS_PORT || "6379"),
      "password": process.env.REDIS_PASSWORD,
      "ttl": 3600,
      "maxMemory": "256mb"
    }
  },
  "monitoring": {
    "metrics": {
      "enabled": true,
      "interval": 60000,
      "retention": "7d"
    },
    "alerts": {
      "errorRate": 0.05,
      "responseTime": 10000,
      "availability": 0.99
    }
  }
};

// Model priority order for failover
export const MODEL_PRIORITY = ['primary', 'secondary', 'validation'] as const;

// Model capabilities mapping
export const MODEL_CAPABILITIES = {
  primary: ['analysis', 'extraction', 'validation', 'generation'],
  secondary: ['analysis', 'extraction', 'validation', 'generation'],
  validation: ['validation', 'quality_check']
} as const;

// Rate limiting configuration
export const RATE_LIMITS = {
  perUser: {
    requestsPerHour: 100,
    requestsPerDay: 500
  },
  global: {
    requestsPerSecond: 10,
    concurrentRequests: 50
  }
} as const;